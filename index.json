
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Hi there!\nI‚Äôm Haoran Hou, from the vibrant city of Tianjin, China. At 22, I‚Äôm on the lookout for a PhD position to dive deeper into my passion for tech.\nMy academic journey kicked off at Tianjin University, where I nailed my undergrad in Electronic Information Engineering with a solid GPA of 88/100. Not one to rest on my laurels, I then zipped over to the prestigious University of Oxford, polishing off their Artificial Intelligence and Machine Learning program in January 2023. Currently, you‚Äôll find me immersed in the world of Human and Biological Robotics at Imperial College London, gunning for a distinction degree with an current average score of 73.8/100 and eyeing a summer 2024 graduation.\nMy time both as an undergrad and postgrad has been packed with research, especially at the intersection of AI and robotics, with a keen focus on making life better for people with disabilities. It‚Äôs been an exhilarating ride, pushing the boundaries of tech to help others, and I‚Äôm just getting started.\n","date":1654041600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1654041600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hi there!\nI‚Äôm Haoran Hou, from the vibrant city of Tianjin, China. At 22, I‚Äôm on the lookout for a PhD position to dive deeper into my passion for tech.","tags":null,"title":"Haoran Hou","type":"authors"},{"authors":["Imperial College London"],"categories":null,"content":"1.MSc Human and Biological Robotics Individual Project\nMachine learning for 3D segmentation of large datasets to detect normal and pathological hearts\n2.Medical Device Entrepreneurship ‚Ä¶‚Ä¶66/100\n3.Statistics and Data Analysis ‚Ä¶‚Ä¶90/100\n4.Reinforcement Learning ‚Ä¶‚Ä¶66/100\n5.Systems Physiology ‚Ä¶‚Ä¶81/100\n6.Brain Machine Interfaces\n7.Image Processing\n8.Application Specific Integrated Circuits for Bioengineers\n9.Animal Locomotion and Bioinspired Robots\n10.Robotics ‚Ä¶‚Ä¶66/100\n11.Human Neuromechanical Control and Learning\n","date":1709769600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709769600,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://example.com/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"1.MSc Human and Biological Robotics Individual Project\nMachine learning for 3D segmentation of large datasets to detect normal and pathological hearts\n2.Medical Device Entrepreneurship ‚Ä¶‚Ä¶66/100\n3.Statistics and Data Analysis ‚Ä¶‚Ä¶90/100","tags":null,"title":"MSc in Human and Biological Robotics","type":"publication"},{"authors":["University of Oxford"],"categories":null,"content":"Please view the PDF for Certificate.\n","date":1693526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693526400,"objectID":"eac55319901285fd94717caa0c2c5261","permalink":"https://example.com/publication/journal-article-copy/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/publication/journal-article-copy/","section":"publication","summary":"Please view the PDF for Certificate.","tags":null,"title":"Program about Artificial Intelligence and Machine Learning","type":"publication"},{"authors":["Tianjin University"],"categories":null,"content":"Please view the PDF for undergraduate transcripts.\n","date":1688169600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688169600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://example.com/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Please view the PDF for undergraduate transcripts.","tags":null,"title":"BSc in Electronic Information Engineering","type":"publication"},{"authors":["Haoran Hou","Zhouhao Jiang"],"categories":null,"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654041600,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://example.com/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Proceedings of the 2022 2nd International Conference on Control and Intelligent Robotics, p. 91-101. doi:10.1145/3548608.3559175","tags":[],"title":"Design and simulation of an upper limb rehabilitation exoskeleton robot","type":"publication"},{"authors":["Haoran Hou","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"import libr print(\u0026#39;hello\u0026#39;) Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://example.com/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Hugo Blox Builder, the website builder for Hugo","type":"post"},{"authors":null,"categories":null,"content":"Hugo Blox Builder is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you‚Äôll find some examples of the types of technical content that can be rendered with Wowchemy.\nExamples Code Wowchemy supports a Markdown extension for highlighting code syntax. You can customize the styles under the syntax_highlighter option in your config/_default/params.yaml file.\n```python\rimport pandas as pd\rdata = pd.read_csv(\u0026#34;data.csv\u0026#34;)\rdata.head()\r```\rrenders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Mindmaps Wowchemy supports a Markdown extension for mindmaps.\nSimply insert a Markdown markmap code block and optionally set the height of the mindmap as shown in the example below.\nA simple mindmap defined as a Markdown list:\n```markmap {height=\u0026#34;200px\u0026#34;}\r- Hugo Modules\r- wowchemy\r- blox-plugins-netlify\r- blox-plugins-netlify-cms\r- blox-plugins-reveal\r```\rrenders as\n- Hugo Modules\r- wowchemy\r- blox-plugins-netlify\r- blox-plugins-netlify-cms\r- blox-plugins-reveal A more advanced mindmap with formatting, code blocks, and math:\n```markmap\r- Mindmaps\r- Links\r- [Wowchemy Docs](https://docs.hugoblox.com/)\r- [Discord Community](https://discord.gg/z8wNYzb)\r- [GitHub](https://github.com/HugoBlox/hugo-blox-builder)\r- Features\r- Markdown formatting\r- **inline** ~~text~~ *styles*\r- multiline\rtext\r- `inline code`\r-\r```js\rconsole.log(\u0026#39;hello\u0026#39;);\rconsole.log(\u0026#39;code block\u0026#39;);\r```\r- Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$\r```\rrenders as\n- Mindmaps\r- Links\r- [Wowchemy Docs](https://docs.hugoblox.com/)\r- [Discord Community](https://discord.gg/z8wNYzb)\r- [GitHub](https://github.com/HugoBlox/hugo-blox-builder)\r- Features\r- Markdown formatting\r- **inline** ~~text~~ *styles*\r- multiline\rtext\r- `inline code`\r-\r```js\rconsole.log(\u0026#39;hello\u0026#39;);\rconsole.log(\u0026#39;code block\u0026#39;);\r```\r- Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ Charts Wowchemy supports the popular Plotly format for interactive charts.\nSave your Plotly JSON in your page folder, for example line-chart.json, and then add the {{\u0026lt; chart data=\u0026#34;line-chart\u0026#34; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\nYou might also find the Plotly JSON Editor useful.\nMath Wowchemy supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.yaml file.\nTo render inline or block math, wrap your LaTeX math with {{\u0026lt; math \u0026gt;}}$...${{\u0026lt; /math \u0026gt;}} or {{\u0026lt; math \u0026gt;}}$$...$${{\u0026lt; /math \u0026gt;}}, respectively. (We wrap the LaTeX math in the Wowchemy math shortcode to prevent Hugo rendering our math as Markdown. The math shortcode is new in v5.5-dev.)\nExample math block:\n{{\u0026lt; math \u0026gt;}} $$ \\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2} $$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$\rExample inline math {{\u0026lt; math \u0026gt;}}$\\nabla F(\\mathbf{x}_{n})${{\u0026lt; /math \u0026gt;}} renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the math linebreak (\\\\):\n{{\u0026lt; math \u0026gt;}} $$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\rf(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\\r1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}\r$$\rDiagrams Wowchemy supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid\rgraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2]\r```\rrenders as\ngraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid\rsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good!\r```\rrenders as\nsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid\rgantt\rsection Section\rCompleted :done, des1, 2014-01-06,2014-01-08\rActive :active, des2, 2014-01-07, 3d\rParallel 1 : des3, after des1, 1d\rParallel 2 : des4, after des1, 1d\rParallel 3 : des5, after des3, 1d\rParallel 4 : des6, after des4, 1d\r```\rrenders as\ngantt\rsection ‚Ä¶","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://example.com/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Hugo Blox Builder is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Markdown","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Hugo Blox Builder Hugo Blox Builder | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://example.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Hugo Blox Builder's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Abstract This project aims to accelerate the upper limb rehabilitation speed for hemiplegia and disability caused by stroke and other diseases and designs an arm-assisted rehabilitation exoskeleton robot. According to the standard size of the human upper limb, the 3D model of the upper limb exoskeleton robot was designed in SolidWorks, and the DH parameters and kinematics equations of the robot were derived. By studying the arm posture of human upper limb movement, the state and data of each joint in the upper limb movement were analyzed. It was carried out in MATLAB to simulate the structure of the rehabilitation manipulator, analyze the motion trajectory planning, and verify the rationality of the robot‚Äôs joint movement. This paper combines the 3D model and the MATLAB simulation, the upper limb rehabilitation of the exoskeleton robot arm, lower arm, shoulder, elbow, and wrist joints working space, the kinematics, and the arm in various trajectory planning of posture were solved. It provides a theoretical basis and flexibility for improving the accuracy of upper limb rehabilitation.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://example.com/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"Research on Robotics and Automation","tags":["Robotics"],"title":"a) Chinese Academy of Sciences","type":"project"},{"authors":null,"categories":null,"content":"Abstract To enable blind people to perceive surrounding obstacles in real-time while traveling and improve the safety of blind people‚Äôs travel, traditional blind walking sticks have been modified. This article adopts the STM32f103zet6 microcontroller and uses embedded development design to add functions such as ultrasonic obstacle avoidance, GPS positioning, fall detection, fingerprint unlocking, and voice broadcasting to the traditional blind cane. This project utilizes the XFS5152CE chip to achieve voice broadcasting function, the AS608 optical fingerprint module to achieve fingerprint unlocking function, the ESP8266WiFi module to achieve interaction between mobile phones and intelligent guide canes, the ADXL345 module to detect the user‚Äôs status in real-time, and to achieve fall warning function. The ultrasonic obstacle avoidance module utilizes the principle of ultrasonic ranging. The GPS positioning module can receive and demodulate the broadcast C/A code signal of satellites, and achieve GPS positioning function by calculating the pseudo distance to each satellite and calculating parameters such as longitude and latitude. The feasibility of this scheme has been verified through experiments. Fingerprint unlocking, voice broadcasting, and GPS positioning functions can all operate normally. When the distance between the guide rod and the obstacle is less than 0.2m, or the forward acceleration in a certain direction of the guide rod is too large, the intelligent guide rod can send out a warning signal in a timely manner.\nKEY WORDS: STM32 microcontroller, intelligent blind cane, ultrasonic ranging, GPS, embedded Introduction 1.1 Project Overview 1.1.1 Introduction to the Project\nAs one of the assistive tools for mobility, guide canes are widely used among the blind community. In today‚Äôs technologically advanced world, the trend towards product intelligence is undeniable. Taking into consideration the overall environment of the pandemic and the daily mobility needs of the blind, this project is dedicated to designing an intelligent guide cane to further facilitate the mobility of the blind. By adding only a small amount of cost, the guide cane is equipped with an ultrasonic obstacle avoidance system, a GPS positioning system, a fall detection with one-click alarm feature, a display screen that can show personal health codes and payment codes, a voice broadcast for daily weather forecasts, and a fingerprint lock to protect important personal information such as health codes and payment codes.\n1.2 Project Plan 1.2.1 Background of the Project\nAccording to statistics from the Ministry of Health, there are as many as 14 million blind people in China, making it the country with the highest number of blind individuals in the world. On average, there is one blind person in every 100 individuals. Every year, about 450,000 new cases of blindness and visually impaired individuals are reported in China, highlighting an urgent need to address their mobility issues. The factors affecting the lives of the blind mainly include the following:\nFirst, the physical defects of the blind lead to many disadvantages in their lives; Second, due to mobility challenges, the blind find it difficult to interact with the outside world, lacking in entertainment and social interactions. Third, due to their physical disabilities, the blind face unequal treatment in social work and interpersonal interactions compared to sighted individuals.\nDue to visual impairments, the blind community has developed a communication mode different from sighted individuals for perceiving the world and conveying information.\nSurveys show that only 27% of blind individuals go out daily, 55% of them are unable to distinguish directions while traveling, and 34% worry about colliding with obstacles during their journeys. The survey concluded that the main reason for the low mobility of blind individuals is the lack of a comprehensive transportation system and friendly navigation devices, along with the low utilization rate of blind paths. There is a general desire among the blind for friendly mobility tools to ensure their safety, a dedicated transportation system for the blind, and the introduction of high-tech products for better navigation and assistance.\n1.2.2 Significance of the Project\nFirstly, the inability of the blind to easily venture outdoors hinders their interaction with the external world. Products such as blind navigators can facilitate their mobility, increase safety, and make their travels less tedious, thereby helping blind individuals integrate into modern intelligent life.\nSecondly, in the context of big data, artificial intelligence, and 5G, relying on advanced scientific and technological means to solve the mobility issues of the blind is of great significance. The blind hope to be treated equally by others, to not be isolated, and to participate in social life and activities just like sighted people. Hence, there is a strong desire for ‚Ä¶","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://example.com/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"Research and Development of Intelligent Crutch Based on STM 32","tags":["Artificial Intelligence"],"title":"b) Innovation \u0026 Entrepreneurship Training Program for College Students","type":"project"},{"authors":null,"categories":null,"content":"Project Specification Cardiovascular disease (CVD) is well recognized as the leading cause of death and a significant danger to global public health. In 2016, the World Health Organization reported that CVD was responsible for 31% of all annual deaths, totaling over 18 million individuals, with a continuous increase each year¬†[1]. Recently, the medical field has consistently worked to decrease the death rate from heart illness and enhance the diagnosis of cardiac conditions.\nMammalian models, including pigs, non-human primates, and rodents, have been primarily utilized to study the processes of heart disease. Conversely, there is a growing trend to decrease the utilization of mammals for research purposes and implement alternative models. Zebrafish have emerged as a robust model for investigating heart development and morphology based on recent advancements, because Zebrafish are tiny, easy to breed, reach sexual maturity early, and have external translucent embryo development for easy viewing [2]. The cardiovascular system of zebrafish is similar to that of mammals in terms of anatomy and physiological function. The heart of zebrafish is also composed of atria and ventricle, with the valve between the atria and the ventricle. The development and gene regulation mechanism of the heart are also similar to human [3]. Although the zebrafish heart is relatively simple compared to mammals, most specialized cell types and structures (e.g., pacemaker, atrioventricular valve, aortic valve, trabeculae, and coronary vessels) and contributing cell types (myocardium, endocardium, epicardium, cardiac neural crest, second heart field, and fibroblasts) are preserved [4].\nAt the same time, more advanced imaging methods in medical image can also promote the advancement of cardiovascular diagnosis and research. For example, with the help of advanced technologies such as light-sheet fluorescence microscopy (LSFM) (as shown in Figure 1(a)), medical researchers can obtain higher quality and resolution cardiac images. Unlike traditional epifluorescence microscopy (as shown in Figure 1(b)), LSFM uses orthogonal independent excitation and detection light paths to thinly illuminate the sample from the side, excite only the fluorescence in the sample, and then detect the image in the orthogonal direction [5]. This method effectively avoids the impact of out-of-focus background on image quality, improves imaging contrast, and makes in-depth research and accurate diagnosis of heart disease possible. The application of LSFM mainly focuses on three aspects: cell biology [7]‚Äå, developmental biology [8] and neuroscience¬†[9]. As the first functional organ formed during mammalian embryonic development, the heart is a key driving force for the development of other tissues and organs. In order to better understand cardiac morphogenesis and to more effectively treat cardiovascular diseases, many researchers use this microscope to study the heart. Yue et al. used light-sheet imaging technology to reconstruct the whole cell lineage with single-cell resolution and temporal continuity [10]. They reported for the first time a panoramic view of the cell lineage during the early development of the mammalian heart, revealing the process from the origin of the heart tube to the establishment of the ventricle, and then to a new mechanism of cellular dynamics of myotrabecular formation; Lovelace et al. used the HYBRiD tissue clearing method and high-resolution light sheet microscopy to observe the distribution of a large number of NPY2R VSN fibers in the ventricular wall, providing an intuitive experimental model for in-depth exploration of cardiac sensory neurons in physiological and pathological states [11].\nCardiac image segmentation is a critical step in processing cardiac images. With the continuous advancement of deep learning algorithms, it has become possible to divide images into anatomically meaningful regions and extract quantitative measurements from them. However, although deep learning has better feature recognition and extraction capabilities than traditional methods, medical image segmentation poses significant challenges due to the complexity of medical images, such as class imbalance, interference from neighboring organs, lack of high-quality annotations, and label noise. Over the years, segmentation algorithms based on models such as convolutional neural networks (CNN) [12] and fully convolutional networks (FCN) [13] have continued to advance.\nThis project aims to develop a data analysis pipeline to segment normal and pathological hearts based on their 3D morphological changes. First, this project will develop an image analysis method to reconstruct 2D time series into 4D data and robustly quantify the 3D morphology of the heart using the large 2D imaging data set collected by the Vermot Laboratory. Subsequently, the project will develop and train a segmentation network based on deep learning to identify cell nuclei and track position ‚Ä¶","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"3872c15b287c5b9c7bb446ff972dbd81","permalink":"https://example.com/project/external-project-copy-4/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project-copy-4/","section":"project","summary":"Machine learning for 3D segmentation of large datasets to detect normal and pathological hearts","tags":["Artificial Intelligence"],"title":"c) Master‚Äôs thesis project","type":"project"},{"authors":null,"categories":null,"content":"ABSTRACT The purpose of human motion detection is to provide a system for self-analysis of events in the video data and to understand the behaviour of a person. This is a key function of intelligent video surveillance systems with a wide range of applications. In this paper, we investigate a human action recognition system based on two steps of human feature extraction and human action classification. Quantification and model transplantation for the human feature extraction step are performed based on an artificial intelligence chip.\nTo complete the human feature extraction, a humanoid target detector is first built based on the YOLOv5s framework and DeepSORT tracking, and a pose estimation detector is built to extract human bone joint points using the Alphapose algorithm. The extracted features are then fed into the action classification detector based on convolution of spatio-temporal maps to complete the construction of the human motion recognition system.\nDue to the problems of aerial perspective and complex background of surveillance videos, this work does not use the current mainstream dataset, but uses several high-resolution surveillance cameras from the Experimental Teaching Center of Information and Communication Engineering, School of Electrical Automation and Information Engineering, Tianjin University to create a 15-hour dataset with 9 types of actions in 12 indoor and outdoor scenes to train and evaluate the model. In this work, the feasibility of this human motion recognition system is verified by experiment, and its average accuracy can reach 95%, and it meets the real-time requirements.\nFinally, in this work, the embedded AR9341 chip is used as the model support to quantify and transplant the model to the human feature extraction phase, and the NPU module provided by the platform is used for acceleration, so that the human feature extraction system can have high accuracy, faster speed and a wider range of application scenarios.\nKEY WORDS: Object detection, Pose estimation, Action recognition, Artificial intelligence chip, Model quantization and transplantation ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"0d3caca31b584449a0fa977260cf2378","permalink":"https://example.com/project/external-project-copy-3/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project-copy-3/","section":"project","summary":"Human Action Recognition Module Design and Embedded AI Transplantation in Video Surveillance Systems","tags":["Artificial Intelligence"],"title":"d) Undergraduate graduation project","type":"project"},{"authors":null,"categories":null,"content":"Project Overview This project develops an efficient mask detection system using Python, designed to autonomously identify whether individuals are wearing masks. Originating from the global COVID-19 pandemic in 2019, the context highlights the necessity of mask-wearing in public areas and the urgent need for automated systems to reduce the burden on manual checks.\nDevelopment Tools and Technical Approach Utilizing the Python IDE PyCharm and the image annotation tool Labelme as primary development and data processing tools, the project employs machine learning algorithms‚Äîspecifically, the MobileNet framework‚Äîfor in-depth training and optimization. Experimental methods include data preprocessing, model training, and testing validation, ensuring the system‚Äôs accuracy and practicality.\nCode Implementation and Performance Optimization The summary details the process from data set construction and model architecture establishment to the implementation of training strategies, emphasizing optimization measures taken during model training, such as dynamic learning rate adjustments and early stopping. These measures significantly enhance the model‚Äôs generalization ability and recognition accuracy.\nResults Display and Application Value Experimental outcomes demonstrate the system‚Äôs effective recognition of mask-wearing status in real-time video streams, validating the model‚Äôs effectiveness. The mask detection system not only achieves the technical objectives but also holds significant application potential in the field of public health management.\nConclusion This project showcases the powerful application capabilities of deep learning in the public health domain, particularly against the backdrop of the current global pandemic. The development of the mask detection system bears important social value and practical significance. With continuous technological advancement and optimization, the system is expected to play a larger role in a broader range of scenarios.\nThis summary aims to provide web viewers with a clear, professional perspective on the project‚Äôs core values and technical details.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"2825294ec8d0848d6b20f6bd5f58b747","permalink":"https://example.com/project/external-project-copy-8/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project-copy-8/","section":"project","summary":"Epidemic prevention and control system for elevators","tags":["Artificial Intelligence"],"title":"e) Machine learning and visual perception","type":"project"},{"authors":null,"categories":null,"content":"Project Background The intelligent vehicle, or wheeled mobile robot, integrates multiple functions such as environmental sensing, planning and decision-making, and autonomous driving into a comprehensive system. Aimed at enhancing future lifestyles with smarter solutions, this technology is applicable not only in military contexts but also in scientific research, intelligent rescue, and more. The vehicle‚Äôs mechanical structure comprises the body, wheels, speed sensors, rotational axles, equipped with a power driver and a camera module for environmental data collection.\nDesign Scheme Overview Employing a PID control algorithm and a CCD linear camera for black line guidance detection, processed by an LM393 comparator for microcontroller-based data collection and image recognition, this design enables path identification. Motor drive is facilitated by the PC33886 model, with speed measured by direct photoelectric sensors, and data displayed on an LCD screen. Four button keys are utilized for parameter settings, enhancing the user interface for onsite debugging. The project ingeniously incorporates a mix of photonic, mechanical, and wireless communication technologies.\nStructural and System Design Based on the principles of autonomous guide robot systems, the intelligent car is capable of autonomously recognizing and following predetermined paths. The main control module uses the STC89C51 microcontroller, focusing on centralized control and modular design, incorporating infrared sensor line tracking and trajectory detection modules. The mechanical structure is designed to minimize external light interference, ensuring balanced and stable navigation.\nHardware System Construction The system‚Äôs hardware includes the STM32F103 microcontroller as the main control module, along with power, motor drive, infrared obstacle avoidance, control terminal, and wireless video monitoring modules. This setup ensures reliable power supply and effective control over the vehicle‚Äôs dynamic monitoring functions.\nProgramming Challenges and Solutions The report also delves into the learning process for programming the STM32 microcontroller, including clock initialization, mobility function implementation, PID algorithm development, steering functionality, Bluetooth serial port configuration, and PID debugging. By exploring sensor detection, PWM output for motor driving, speed detection, and serial communication, the project overcame various developmental challenges.\nProject Summary Through teamwork, we successfully assembled the intelligent car and achieved the line-tracking task. Throughout the project, we solved multiple technical problems, gaining an in-depth understanding of the working principles of intelligent cars and mastering STM32 related skills. This experience not only enhanced our practical abilities but also strengthened our team collaboration spirit. This course has provided us with invaluable and enriching learning, contributing significantly to our academic and practical growth.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"612676e86aed598af3351e4ee0545968","permalink":"https://example.com/project/external-project-copy/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project-copy/","section":"project","summary":"Develop a tracking and obstacle avoidance car based on STM32","tags":["Electronic"],"title":"f) Electronic system design","type":"project"},{"authors":null,"categories":null,"content":"1. Design description: The basic function of this design is to collect temperature and humidity, then collect light intensity (as the input signal part), and then display these three values on the digital tube (as the output signal part). Then set the upper limit value in the program, and the buzzer will alarm when the upper limit value is exceeded.\nIn the simulation part, a light bulb and a photoresistor are used to simulate a light sensor. The voltage across the photoresistor is obtained to represent the light intensity. Then an operational amplifier is used to make the change in light intensity and voltage within a certain range have a linear relationship. At this time, the light obtained Strong is just an analog value, which is then input to the PF0 port of ATmega64 for the next step of analog-to-digital conversion; in addition, similar to the photosensitive part, the temperature sensitive part uses a light bulb plus a thermosensitive resistor to simulate the temperature sensor; the humidity part uses pulse voltage frequency simulation Humidity, the humidity value we obtain at this time is already a digital quantity, which can be directly input into the PD6 port of ATmega64. The quantities we input will be used for subsequent display on the LM016L and for alarming when the set threshold is exceeded.\nIn addition, in the output part, we use LM016L for display, which displays digital quantities, and then switches the display and sets the alarm threshold through buttons.\nFor the working voltage part, except the buzzer alarm which uses DC +12V voltage, the rest uses the DC +5V voltage output by LM7805. Then the working voltage of ATmega64 is 4.5V to 5.5V, the working voltage of temperature and humidity sensor is 5V, the maximum working voltage of photodiode is generally 10 to 50V, the best working voltage of LM016L module is 5V, whichever of the above devices can work The voltage is 5V as the supply voltage. And due to the limitations of the device LM016L, the operating current is 2mA.\n2. Electrical schematic diagram: 3. Printed board diagram: ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"fe9725e95dab45066056cc1b7015b18b","permalink":"https://example.com/project/external-project-copy-5/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project-copy-5/","section":"project","summary":"Temperature and humidity alarm \u0026 light intensity display","tags":["Electronic"],"title":"g) Proteus electronic system design and simulation","type":"project"},{"authors":null,"categories":null,"content":"I. Functionality Transmitter Side: The user inputs the mathematical expression to be calculated through buttons. The expression can include basic operations such as addition, subtraction, multiplication, and division (complex calculations can be added similarly). Then, the process of Encoding ‚Üí Modulating ‚Üí Sending is executed. After sending, the device immediately enters a waiting mode, awaiting a response from the receiver side.\nReceiver Side: The receiver side is in a waiting state from the start. Upon receiving a signal, it automatically performs demodulation, calculation, encoding, modulation, and then sends a response.\nOther Buttons: The ‚ÄúCarrier 1‚Äù and ‚ÄúCarrier 2‚Äù buttons can display the waveform of the carrier on the right side of the image. The processes of encoding, modulation, and reception will be shown on the waveform graph on the right side, displaying the time-domain waveform. The introduction button provides a simple explanation of the principles. The ‚Äústop‚Äù button is used to interrupt detection, and the ‚Äúout‚Äù button is used to exit this window.\nII. Principle and implementation Encoding Source Encoding: As shown in Figure, the wireless calculator is designed with 16 input buttons, which is the 4th power of 2.\nChannel Encoding: Why use Hamming encoding for the information bits? The answer is that Hamming encoding is an efficient linear block code capable of correcting single-bit errors. The 7,4 Hamming code adds three check bits to a group of 4-bit information bits and can correct minor errors through the calculation of syndromes or correction factors. This enhances the communication system‚Äôs resistance to interference, as detailed in the textbook on page 261.\nFrame Synchronization and Protection Codes: The purpose of frame synchronization is to determine the sampling moments for each bit. The frame synchronization code here is used to inform the receiving end when the valid information begins and to establish the starting moment for sampling. Barker codes, with their sharp autocorrelation peak, facilitate identification and minimize the likelihood of false synchronization. The receiver‚Äôs identification method is also simple, hence the choice of Barker codes as the true synchronization codes.\nGiven the variable length of the information bits transmitted in this system, the receiver cannot determine when to end sampling, so a Barker code is also added at the end to accurately extract the middle information bits. The role of the protection code is to\nprovide energy variation for the receiver to detect energy changes, and to prevent the delay in calculation from omitting useful information bits, offering the computer a buffer time.\nModulation The modulation method is 2FSK.\nFirst, the sampling frequency needs to be determined. It is best if the sampling frequency is consistent with the MATLAB sound function, hence 8000Hz is chosen here.\nNext, determine the bit transmission rate RB. Generally, a lower transmission rate results in higher accuracy but lower efficiency. Thus, a compromise is chosen at 100Hz. Given a sampling frequency of 8000, this means fs=100Hz and each bit is expanded to 80 samples (8000/80 = 100Hz). The normalized frequency is 0.025œÄ, and the time-domain waveform and spectrum of the transmitted bits are as follows:\nThen, determine the frequencies for carrier 1 and carrier 2. When selecting frequencies, it‚Äôs important that the main lobes of the frequency spectra for carrier 1 and carrier 2 overlap as little as possible after modulation. The width of the lobes on either side is fs, so there should be a gap of 2fs between the two carrier frequencies. Considering phase continuity, the frequencies should have an even ratio to simplify calculations and programming without the need to consider phase discontinuities. Furthermore, they should be below half the sampling frequency to satisfy the sampling theorem, i.e., below 4000Hz. Hence, 1000Hz and 2000Hz are chosen, with normalized frequencies of 0.25œÄ and 0.5œÄ respectively.\nThe modulation method involves modulating each bit (before expansion) into 80 points (corresponding to a sampling frequency of 8000, or 100Hz). If a bit is 1, then a 2000Hz sine wave repeating 20 times is used as the modulation waveform (2000/20=100Hz); if a bit is 0, then a 1000Hz sine wave repeating 10 times is used (1000/10=100Hz).\nReception and Demodulation It is important to note that the steps for demodulation are the reverse of those for modulation and correspond one-to-one.\nThe reception uses an energy detection method, which is simply a process of multiplying corresponding elements of matrices and summing them up to check if they reach a threshold value. 2FSK Non-coherent Demodulation The choice of non-coherent demodulation for 2FSK arises from the fact that coherent demodulation involves a multiplication process. At the selection stage, non-coherent demodulation was chosen because if it involves multiplication, the chance of coding errors increases ‚Ä¶","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"214ce39e09e6b24b4d98c80c1e2670a8","permalink":"https://example.com/project/external-project-copy-7/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project-copy-7/","section":"project","summary":"Wireless calculator design","tags":["Electronic"],"title":"h) Communication Principle","type":"project"},{"authors":null,"categories":null,"content":"I was particularly engaged by the electronic system design courses, since I could build up my practical capability and build on the theoretical. We also the used single chip microcomputer 80C51F020 to generate a digital sine wave that could control the amplitude and frequency changes via keyboard and output stable sine wave by 12-bit DAC. From the design and simulation of the hardware circuit, to the layout and welding of the circuit board, and then to the design and debugging of the software part of the MCU, we designed a digital synthesis signal device.\nSynopsis of Digital Synthesizer Creation Objective and Innovation: At the core of this endeavor was the ambition to construct a digital synthesizer capable of generating sine waves, with enhanced user control over amplitude and frequency modulation. The project‚Äôs cornerstone was the adept use of the 80C51F020 microcontroller, showcasing an astute application of digital-to-analog conversion techniques to engineer precise and adjustable electronic signals.\nTechnical Mastery and Application Signal Range and Modulation: The project‚Äôs specification to adjust signal frequencies between 1Hz to 100Hz, alongside amplitude variations from 0.3V to 3Vp-p, demonstrates a rigorous and calculated approach to electronic signal manipulation. This precision underscores the team‚Äôs dedication to creating adaptable and user-centric electronic solutions.\nMicrocontroller Utilization: Employing the C8051F020‚Äôs 12-bit DAC was a strategic choice, spotlighting the project‚Äôs innovative use of microcontroller capabilities to ensure signal accuracy. This decision reflects a harmonious fusion of software-driven logic with the tangible dynamics of hardware execution.\nConvergence of Hardware and Software Design Comprehensive System Development: The project narrative delineates the transition from conceptual circuit design to the practical assembly and detailed microcontroller software debugging. This extensive process underscores the team‚Äôs proficiency in electronic system realization, encompassing a broad spectrum of engineering skills.\nAdvanced Signal Processing: Utilizing MATLAB for generating sine wave samples and their quantization for DAC implementation is indicative of an advanced approach to signal processing. This methodology bridges theoretical concepts with real-world technological applications, enriching the project‚Äôs technical depth.\nDesign requirements (function and indicator description) Signal frequency range: 1Hz-100Hz; step: 1Hz; accuracy: +/-5% (the above indicators are measured at room temperature) Signal amplitude: 0.3V-3Vp-p; step: 0.1V; accuracy: +/-10% (the above indicators are measured at room temperature) Load capacity: can drive 10 ohm pure group load Frequency and amplitude can be displayed through LED digital tube (can be displayed alternately through indicator lights) Effective when the keyboard is raised System hardware schematic diagram The following figure shows the simulation schematic diagram on Tina Key technical points of hardware modules DAC module This experiment uses C8051F020 built-in 12-bit voltage output DAC, which has the following main features:\nThe voltage reference of each DAC is provided at the VREFD or VREF pin.\rEach DAC has a flexible output update mechanism that allows seamless full-scale changes and supports jitter-free output updates.\rThe data and control interface between the MCU and each comparator and DAC are implemented through special registers\rThe main indicators of DAC: 12bit resolution:\nOutput setup time: 10us\rOutput voltage range: 0~VREF-1LSB\rOutput short circuit current: 15mA\rAnd we tried to use Tina simulation software to build a DAC module that can output stepped sine waves, so that we can verify the feasibility of subsequent modules on the software, especially the quality of the filtering effect.\nFilter module Generate a second-order Bessel low-pass filter through filter pro, and the parameter settings are as shown in the figure below.\nThis circuit module generates a clock signal, DACO generates a ladder signal, inputs an eighth-order ladder wave through DACO, and CLK inputs a clock signal of 100:1 (clock signal frequency: sinusoidal signal frequency) to achieve the function of the filter.\n(1) The signal frequency is adjustable. The signal frequency is controlled by changing the frequency of the ladder signal generated by DACO and changing the frequency of the signal in the CLK generation formula through program control. The highest frequency output that can be achieved is 2000Hz, and it has stable frequency output.\n(2) Signal phase modulation.\nBy selecting the DACO phase to output, digital phase modulation is achieved. The 0 phase is used when the number is 0 and the T phase is used when the number is 1.\nPower amplifier module A DC-blocking capacitor C4 is added before the power amplifier module to prevent the filter module and the power amplifier from affecting each other. , in order to prevent the base current from being ‚Ä¶","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"06adda1ba2daca7e9051355e569ec48b","permalink":"https://example.com/project/external-project-copy-9/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project-copy-9/","section":"project","summary":"Digital Synthesizer","tags":["Electronic"],"title":"i) Electronic system design and simulation","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://example.com/talk/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/","section":"event","summary":"","tags":null,"title":"","type":"event"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"https://example.com/privacy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/privacy/","section":"","summary":"","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9b10c1f64082d3869fd4cb1f85809430","permalink":"https://example.com/terms/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/terms/","section":"","summary":"","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Organize your notebooks Place the notebooks that you would like to publish in a notebooks folder at the root of your website.\nOrganize your notebooks The notebooks will be published to the folder you specify above. In this case, they will be published to your content/post/ folder.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"94fa5e486d3bf3e0941e2ff6e7126c06","permalink":"https://example.com/post/blog-with-jupyter/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/blog-with-jupyter/","section":"post","summary":"Relevant courses and grades","tags":null,"title":"Master - Imperial College London - Human and Biological robotics","type":"post"}]